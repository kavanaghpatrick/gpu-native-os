# GPU-Native OS

A single-threadgroup operating system running entirely on the GPU via Metal compute shaders.

## Overview

This project explores a radical approach to application architecture: instead of the CPU orchestrating rendering with GPU assistance, **the GPU runs the entire application** — input handling, state updates, layout, and rendering — in a single compute kernel per frame.

All 1024 threads participate in every phase. The CPU's role is minimal: forward input events and submit command buffers.

## GpuApp Framework

The `GpuApp` trait provides a standardized way to build GPU-native applications. Apps implement this trait and run on the `GpuRuntime`, which manages:

- **Input handling** — Keyboard/mouse events forwarded to GPU
- **Memory management** — Unified CPU/GPU buffers
- **Frame timing** — Delta time, frame counting
- **Render pipeline** — Compute → Render → Present

```rust
pub trait GpuApp {
    fn name(&self) -> &str;
    fn compute_pipeline(&self) -> &ComputePipelineState;
    fn render_pipeline(&self) -> &RenderPipelineState;
    fn vertices_buffer(&self) -> &Buffer;
    fn vertex_count(&self) -> usize;
    fn app_buffers(&self) -> Vec<&Buffer>;
    fn params_buffer(&self) -> &Buffer;
    fn update_params(&mut self, frame_state: &FrameState, delta_time: f32);
    fn handle_input(&mut self, event: &InputEvent);
}
```

### Buffer Slot Convention

All apps follow a standardized buffer binding:

| Slot | Buffer | Purpose |
|------|--------|---------|
| 0 | FrameState | OS-provided: cursor, time, frame number |
| 1 | InputQueue | OS-provided: keyboard/mouse events |
| 2 | AppParams | App-specific per-frame parameters |
| 3+ | App buffers | App-specific state |

### Frame Execution

Each frame, `GpuRuntime` executes:

```
1. Update timing (delta_time, frame_count)
2. Process input events → forward to app
3. App updates params buffer
4. COMPUTE PASS: dispatch app kernel (1024 threads)
5. RENDER PASS: draw vertices generated by compute
6. Present drawable
```

## Demo Applications

### Simulations

| Demo | Description | Command |
|------|-------------|---------|
| **Waves** | 256x256 wave simulation with ripple effects | `cargo run --release --example waves` |
| **Boids** | 1024-boid flocking (separation, alignment, cohesion) | `cargo run --release --example boids` |
| **Particles** | 10K+ particle physics with mouse interaction | `cargo run --release --example particles` |
| **Metaballs** | Organic blob animation with implicit surfaces | `cargo run --release --example metaballs` |
| **Game of Life** | Conway's cellular automaton (32x32 grid) | `cargo run --release --example game_of_life` |

### Interactive Apps

| Demo | Description | Command |
|------|-------------|---------|
| **Mandelbrot** | Fractal viewer with 10 preset locations | `cargo run --release --example mandelbrot` |
| **Text Editor** | Full text editor with GPU-rendered font | `cargo run --release --example text_editor` |

### Mandelbrot Controls
- **Scroll** - Zoom in/out at cursor
- **Click + drag** - Pan
- **1-9, 0** - Jump to preset locations (Seahorse Valley, Double Spiral, Mini Mandelbrot, etc.)
- **R** - Reset view

### Text Editor Controls
- Type to insert, arrow keys to move, Backspace/Delete, Enter for newlines

## Architecture

```
┌──────────────────────────────────────────────────────────────┐
│                        CPU (minimal)                         │
├──────────────────────────────────────────────────────────────┤
│  macOS events → InputHandler → [shared buffer]               │
│  GpuRuntime.run_frame() → compute → render → present         │
└──────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌──────────────────────────────────────────────────────────────┐
│                   GPU (1024 threads, 1 threadgroup)          │
├──────────────────────────────────────────────────────────────┤
│  App Compute Kernel:                                         │
│    Phase 1: Process pending edits/input                      │
│    Phase 2: Update state (cells, document, physics)          │
│    Phase 3: Generate vertex geometry                         │
│                                                              │
│  Render Pass:                                                │
│    Vertex Shader → Fragment Shader → Pixels                  │
└──────────────────────────────────────────────────────────────┘
```

## Why?

**Apple Silicon unified memory** eliminates CPU↔GPU copies. App state lives in shared buffers accessible to both. The GPU reads input, processes state, and renders — all without round-trips.

**Single threadgroup** means all 1024 threads share 32KB of fast threadgroup memory. They can synchronize with barriers and use SIMD operations for parallel reductions.

**Branchless SIMD** keeps all threads executing the same instructions, avoiding warp divergence that kills GPU performance.

## Benchmarks

Measured on Apple M4 Pro. The GPU-Native OS thesis: **"1024 threads doing UI logic together beats 1 CPU thread."**

### Key Finding: GPU Wins on Architecture, Not Raw Speed

| Scenario | Traditional (3 dispatches) | GPU-Native (1 dispatch) | Speedup |
|----------|---------------------------|------------------------|---------|
| 10 widgets | 313 μs | 99 μs | **3.2x GPU** |
| 50 widgets | 270 μs | 99 μs | **2.7x GPU** |
| 200 widgets | 284 μs | 89 μs | **3.2x GPU** |
| 500 widgets | 319 μs | 121 μs | **2.6x GPU** |
| 1000 widgets | 348 μs | 110 μs | **3.2x GPU** |

The win comes from **eliminating CPU→GPU sync points**, not raw compute speed.

### Frame Pipelining: 6.75x Throughput

| Mode | 1000 Frames | FPS |
|------|-------------|-----|
| Serial (wait each frame) | 104.6 ms | 9,562 |
| Pipelined (overlap frames) | 15.5 ms | 64,584 |
| **Speedup** | | **6.75x** |

### Raw GPU Dispatch Overhead

GPU dispatch has ~80-150μs fixed overhead regardless of work size:

| Operation | GPU (μs) | CPU (μs) | Notes |
|-----------|----------|----------|-------|
| Sort 1024 widgets | 117 | 12 | CPU wins raw compute |
| HitTest 2048 widgets | 89 | 1.2 | CPU wins raw compute |

**Conclusion:** GPU-Native wins on *architecture* (fewer sync points, frame pipelining), not raw compute. For real apps with rendering, the compute work is essentially free since the GPU is already busy.

### Run Benchmarks

```bash
# Automated benchmark suite
cargo run --release --example benchmark_auto -- --iterations 100

# Visual real-time comparison
cargo run --release --example benchmark_visual

# Full frame pipeline comparison
cargo run --release --example benchmark_realistic
```

## Pipeline Modes

Apps can choose their latency/throughput tradeoff:

```rust
fn pipeline_mode(&self) -> PipelineMode {
    PipelineMode::HighThroughput  // Simulations: allow frame overlap
    // or
    PipelineMode::LowLatency      // Text editors: minimize input delay
}
```

| Mode | Behavior | Best For |
|------|----------|----------|
| `LowLatency` | Wait for previous frame | Text editors, interactive UI |
| `HighThroughput` | Allow frames to overlap | Simulations, animations, games |

## Requirements

- macOS with Apple Silicon (M1/M2/M3/M4) or AMD GPU
- Rust 1.70+
- Xcode Command Line Tools (for Metal compiler)

## Quick Start

```bash
# Build all examples
cargo build --release

# Run demos (pick your favorite)
cargo run --release --example waves          # Beautiful ripple effects
cargo run --release --example boids          # Mesmerizing flocking
cargo run --release --example particles      # 10K particle physics
cargo run --release --example mandelbrot     # Fractal exploration
cargo run --release --example metaballs      # Organic blobs
cargo run --release --example game_of_life   # Classic cellular automaton
cargo run --release --example text_editor    # GPU-powered text editing

# Run benchmarks
cargo run --release --example benchmark_auto

# Run tests
cargo test
```

## Project Structure

```
src/
├── lib.rs                    # Library entry
└── gpu_os/
    ├── mod.rs                # Module exports
    ├── app.rs                # GpuApp trait + GpuRuntime + PipelineMode
    ├── memory.rs             # GPU buffer allocation
    ├── input.rs              # Input event handling
    ├── vsync.rs              # Frame timing & sync
    │
    ├── # Apps
    ├── waves.rs              # Wave simulation
    ├── boids.rs              # Flocking simulation
    ├── particles.rs          # Particle system
    ├── mandelbrot.rs         # Fractal viewer
    ├── metaballs.rs          # Organic blobs
    ├── game_of_life.rs       # Cellular automaton
    ├── text_editor.rs        # Text editor
    └── benchmark_visual.rs   # Visual benchmark

examples/
├── waves.rs                  # Wave demo runner
├── boids.rs                  # Boids demo runner
├── particles.rs              # Particles demo runner
├── mandelbrot.rs             # Mandelbrot demo runner
├── metaballs.rs              # Metaballs demo runner
├── game_of_life.rs           # Game of Life demo runner
├── text_editor.rs            # Text Editor demo runner
├── benchmark_visual.rs       # Visual benchmark
├── benchmark_auto.rs         # Automated benchmarks
├── benchmark_realistic.rs    # Pipeline comparison
└── benchmark_frame.rs        # Frame throughput test
```

## Creating a New App

1. Create `src/gpu_os/my_app.rs` implementing `GpuApp`
2. Define your compute kernel using `APP_SHADER_HEADER`
3. Create buffers for your app state
4. Implement `update_params()` and `handle_input()`
5. Create `examples/my_app.rs` to run it with `GpuRuntime`

Example skeleton:

```rust
use super::app::{GpuApp, AppBuilder, APP_SHADER_HEADER};

pub struct MyApp {
    compute_pipeline: ComputePipelineState,
    render_pipeline: RenderPipelineState,
    // ... your buffers
}

impl GpuApp for MyApp {
    fn name(&self) -> &str { "My App" }
    // ... implement trait methods
}
```

## Performance (M4 Pro)

| Metric | Measured |
|--------|----------|
| Frame time | ~0.1-0.3 ms (compute only) |
| GPU dispatch overhead | ~80-150 μs |
| Simulations | 3,000-10,000+ FPS potential |
| Input latency | 1 frame (LowLatency mode) |
| Memory | Unified (zero copies) |

## License

MIT

## Acknowledgments

Inspired by Casey Muratori's discussions on GPU-driven UI and Apple's TBDR (Tile-Based Deferred Rendering) architecture.
